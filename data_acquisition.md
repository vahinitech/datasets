# ğŸ“‹ Vahini AI Pen â€” Data Acquisition Guide (v0.2)

## ğŸ§  Objective

To build a high-quality IMU dataset tailored for offline handwriting recognition in regional Indian languages (e.g., Hindi, Telugu), enabling intelligent digital ink conversion and interaction modeling.

---

## âœï¸ Recording Environment

* **User Position**: Seated, comfortable posture at a flat desk
* **Writing Surface**: A4 paper (80â€“100 GSM), backed with 4â€“5 sheets for support
* **Lighting**: Bright, uniform indoor lighting
* **Hand Posture**: Natural grip; start with right-hand users, extend to left-handers

---

## ğŸ–‹ï¸ Digital Pen Setup (Anonymized)

| Module             | Role                                     |
| ------------------ | ---------------------------------------- |
| IMU Unit           | Captures motion, tilt, angular rotation  |
| Environmental Unit | Captures compass/orientation vectors     |
| Pressure Module    | Detects penâ€“surface contact force        |
| BLE MCU            | Streams sensor data wirelessly (via BLE) |

> *Note: Specific sensor brands/models anonymized for vendor-agnostic reproducibility.*

---

## ğŸ—ƒï¸ Data Schema

Each writing session produces:

* `sensor_data.csv`
  Columns: `timestamp`, `acc_x/y/z`, `gyro_x/y/z`, `mag_x/y/z`, `pressure`, `sample_id`

* `labels.csv`
  Format: `char`, `start_time`, `end_time`, `user_id`, `language`

* `calibration.txt`
  Sensor offsets, gain, bias correction (per session)

---

## ğŸª„ Language-Specific Instructions

| Language | Coverage          | Writing Notes                  |
| -------- | ----------------- | ------------------------------ |
| Hindi    | à¤…â€“à¤¹, à¥ , à¤•à¥à¤·, à¤™... | Block + cursive, if applicable |
| Telugu   | à°…â€“à°”, à°•â€“à°¹, à°¦à±à°¦...  | Include vowel-modifiers        |
| English  | Aâ€“Z, aâ€“z          | Standard print + cursive       |

---

## ğŸ¯ Companion App (in development)

* BLE-based connection to the pen
* Displays characters for writing tasks
* Records IMU + pressure + interaction timestamp
* Multilingual UI for participant ease
* Auto-labels character samples per user session

---

## ğŸ” Recording Procedure

1. Character prompt shown on phone/tablet
2. Participant writes on physical paper
3. Sensor stream is recorded with timestamps
4. Optional: â€œMark doneâ€ tap/gesture used for label tagging
5. Proceed to next prompt

<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/058358e7-9ece-49f3-b587-d2a0612ef3b6" />


---

## âœ… Participant Guidelines

* Write **one character per session**
* Maintain **natural handwriting speed**
* Pen cap off; tip aligned before each trial
* Keep strokes within printable area (optional guide)

---

## ğŸ§ª Data Validation

* Manual spot checks for drift, mislabeling
* Optional preprocessing: `split_characters.py`
* Store datasets in `.pkl` or `.npy` format (Tensor-compatible)

---

## ğŸ“ Folder Format

```
/dataset/
  â”œâ”€â”€ user_01/
  â”‚   â”œâ”€â”€ sensor_data.csv
  â”‚   â”œâ”€â”€ labels.csv
  â”‚   â”œâ”€â”€ calibration.txt
  â”œâ”€â”€ user_02/
  â”‚   â””â”€â”€ ...
```

---

## ğŸ§  Optional: U-Net for Pen-Tip Segmentation

To establish **ground-truth pen trajectory**, optionally integrate:

* **Tablet + external camera setup** (60â€“120 FPS)
* Use **U-Net**-based segmentation model to isolate the pen tip
* Correlate with IMU time-series using synchronized timestamps
* Enables **multi-modal dataset fusion**: camera + IMU

> This pipeline improves recognition granularity but is not mandatory for core IMU dataset development.

---

## ğŸ“Œ Notes

* Minimum **5â€“10 samples per character per user**
* Separate folders for language/script variations
* Dialect annotations encouraged
* Explore **gesture/tap** commands as extended events (`tag="gesture_save"`)
